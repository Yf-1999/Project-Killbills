# -*- coding: utf-8 -*-
"""Data X.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vZWm696ogh_vPrDUVyLZD2KqJPdTTMsJ

#Data X - Classification d’items

### Récupération des données
"""

#Importation des librairies nécessaires
import psycopg2
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# Connexion à la base de données
conn = psycopg2.connect(
    host="prod-rds-db.cbijryjiwdgw.eu-west-3.rds.amazonaws.com",
    user="testdata",
    password="testData678341A",
    database="prodkbdb",
    port=5432
)

# Extraction des données
query = "SELECT  \"itemName\" AS description, type AS category FROM items"
df = pd.read_sql(query, conn)

# Extraction des données
query1 = "SELECT  * FROM items"
df1 = pd.read_sql(query1, conn)
print(df1.head())

# Imprimer les têtes de la table
print(df.head())

# Imprimer la colonne 'description', ce qui détermine le type de ticket de caisse
print(df['description'])

# Le type de ticket de caisse
print(df["category"])

# Prétraitement des données
# Supprimer les champs "None" 
df = df.dropna()

# Vérifier les catégories uniques
unique_categories = df['category'].unique()
print("Catégories uniques :", unique_categories)

"""### Compréhension de la table
Dans la table "items", chaque enregistrement correspondant à un "itemName" possède un type associé. Par exemple, pour l'item "formule boeuf", son type est "menu". Les catégories uniques présentes dans la table sont "menu", "champ vide" et "dish".

Pour cela, nous allons appliquer trois méthodes afin de classifier ces enregistrement (information de type "string") selon leur item.

###Premier modèle (régression logistique multinomiale)

La régression logistique estime la probabilité qu'un événement se produise, tel que voter ou ne pas voter, sur la base d'un ensemble de données donné de variables indépendantes.

Dans notre cas, les catégories uniques sont "menu", "champ vide" et "dish". Car la variable dépendante(item) a trois résultats possibles, nous allons donc utiliser une régression logistique multinomiale.

Afin de convertir les textes en vecteurs numériques, nous allons utiliser la classe TfidfVectorizer (Term Frequency-Inverse Document Frequency). Les textes item sont ensuite convertis en vecteurs numériques (ou matrices) représentant les poids TF-IDF de leurs termes.
"""

# Séparation des données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(df['description'], df['category'], test_size=0.2, random_state=42)

# Création d'un modèle de classification en utilisant la régression logistique)
vectorizer = TfidfVectorizer()
X_train_vectors = vectorizer.fit_transform(X_train)
X_test_vectors = vectorizer.transform(X_test)

# Entraîner le modèle
model = LogisticRegression()
model.fit(X_train_vectors, y_train)

# Évaluation du modèle
y_pred = model.predict(X_test_vectors)
print(classification_report(y_test, y_pred))

"""Le témps d'exécution : 55 seconds

##La régression logistique multinomiale en ajoutant la méthode SMOTE
Cette fois-ci, nous allons appliquer la méthode SMOTE afin d'éliminer l'effet de déséquilibre de répartition de différent type.
"""

from imblearn.over_sampling import SMOTE
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split

# Séparation des données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(df['description'], df['category'], test_size=0.2, random_state=42)

# Vectorisation des données textuelles
vectorizer = TfidfVectorizer()
X_train_vectors = vectorizer.fit_transform(X_train)
X_test_vectors = vectorizer.transform(X_test)

# Appliquer SMOTE pour équilibrer les classes
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train_vectors, y_train)

# Entraîner le modèle avec les données équilibrées
model = LogisticRegression()
model.fit(X_train_res, y_train_res)

# Évaluation du modèle
y_pred = model.predict(X_test_vectors)
print(classification_report(y_test, y_pred))

# Fonction de classification
def classify_item_logistique(item):
    item_vector = vectorizer.transform([item])
    category = model.predict(item_vector)
    return category[0]

"""### La régression logistique multinomiale en ajoutant le nombre d'itérations"""

from imblearn.over_sampling import SMOTE
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split

# Séparation des données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(df['description'], df['category'], test_size=0.2, random_state=42)

# Vectorisation des données textuelles
vectorizer = TfidfVectorizer()
X_train_vectors = vectorizer.fit_transform(X_train)
X_test_vectors = vectorizer.transform(X_test)

# Appliquer SMOTE pour équilibrer les classes
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train_vectors, y_train)

# Entraîner le modèle avec les données équilibrées
model = LogisticRegression(max_iter=1000)
model.fit(X_train_res, y_train_res)

# Évaluation du modèle
y_pred = model.predict(X_test_vectors)
print(classification_report(y_test, y_pred))

"""##Arbres de décision"""

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report
from imblearn.over_sampling import SMOTE

# Séparation des données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(df['description'], df['category'], test_size=0.2, random_state=42)

# Création d'un modèle d'arbre de décision
vectorizer = TfidfVectorizer()
X_train_vectors = vectorizer.fit_transform(X_train)
X_test_vectors = vectorizer.transform(X_test)

# Appliquer SMOTE pour équilibrer les classes
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train_vectors, y_train)

model = DecisionTreeClassifier()
model.fit(X_train_res, y_train_res)

# Évaluation du modèle
y_pred = model.predict(X_test_vectors)
print(classification_report(y_test, y_pred))

# Fonction de classification
def classify_item_arbres(item):
    item_vector = vectorizer.transform([item])
    category = model.predict(item_vector)
    return category[0]

"""# RNN"""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
import tensorflow as tf


# Prétraitement des données
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df['description'])
sequences = tokenizer.texts_to_sequences(df['description'])
X = pad_sequences(sequences)

label_encoder = LabelEncoder()
y = label_encoder.fit_transform(df['category'])

# Séparation des données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Création du modèle RNN
vocab_size = len(tokenizer.word_index) + 1
embedding_dim = 100

model = Sequential()
model.add(Embedding(vocab_size, embedding_dim, input_length=X.shape[1]))
model.add(LSTM(128))
model.add(Dense(len(label_encoder.classes_), activation='softmax'))

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Entraînement du modèle
model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))

# Évaluation du modèle
_, accuracy = model.evaluate(X_test, y_test)
print('Accuracy:', accuracy)